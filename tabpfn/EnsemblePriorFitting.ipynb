{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0204894d",
   "metadata": {},
   "source": [
    "# Ideas: \n",
    "\n",
    "   ## use MoE \n",
    "        - only GP priors (vary generalization / fitting degree)\n",
    "            - much noise -> high generalization \n",
    "            - little noise -> low generalization\n",
    "            - small length scale -> low generalization/ overfitting\n",
    "            - high length scale -> high generalization/ underfitting\n",
    "            \n",
    "        - only MLP priors (vary \"expressiveness\" of model)\n",
    "            - increase mlp hidden dim -> increase expressiveness\n",
    "            - decreas mlp hidden dim -> decrease expressiveness\n",
    "            - increase dropout prob -> generalization\n",
    "            - decrease dropout prob -> overfitting \n",
    "            - change number of causes -> increase / decrease expressiveness\n",
    "        - mixel bag priors\n",
    "            - vary overfitting / generalization \n",
    "            \n",
    "   ## how to choose the different configurations\n",
    "        - random choice \n",
    "        - Bayesian optimization (how?)\n",
    "        - multi fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc4f3a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ed98c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scripts.differentiable_pfn_evaluation import eval_model_range\n",
    "from scripts.model_builder import get_model, get_default_spec, save_model, load_model\n",
    "from scripts.transformer_prediction_interface import transformer_predict, get_params_from_config, load_model_workflow\n",
    "\n",
    "\n",
    "from datasets import load_openml_list, open_cc_dids, open_cc_valid_dids\n",
    "from priors.utils import plot_prior, plot_features\n",
    "from priors.utils import uniform_int_sampler_f\n",
    "\n",
    "from scripts.tabular_metrics import calculate_score_per_method, calculate_score\n",
    "from scripts.tabular_evaluation import evaluate\n",
    "\n",
    "from priors.differentiable_prior import DifferentiableHyperparameterList, draw_random_style, merge_style_with_info\n",
    "from scripts import tabular_metrics\n",
    "from notebook_utils import *\n",
    "\n",
    "from copy import deepcopy\n",
    "from tabpfn.priors.differentiable_prior import replace_differentiable_distributions\n",
    "from ConfigSpace import hyperparameters as CSH\n",
    "import ConfigSpace as CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cabe45f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_datasets = True\n",
    "max_samples = 10000 if large_datasets else 5000\n",
    "bptt = 10000 if large_datasets else 3000\n",
    "suite='cc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c3323d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "base_path = '.'\n",
    "max_features = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26561575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_models(model_string):\n",
    "    print(model_string)\n",
    "\n",
    "    for i in range(80):\n",
    "        for e in range(50):\n",
    "            exists = Path(os.path.join(base_path, f'models_diff/prior_diff_real_checkpoint{model_string}_n_{i}_epoch_{e}.cpkt')).is_file()\n",
    "            if exists:\n",
    "                print(os.path.join(base_path, f'models_diff/prior_diff_real_checkpoint{model_string}_n_{i}_epoch_{e}.cpkt'))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "214595ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(config_sample, i, add_name=''):\n",
    "    start_time = time.time()\n",
    "    N_epochs_to_save = 50\n",
    "    \n",
    "    def save_callback(model, epoch):\n",
    "        if not hasattr(model, 'last_saved_epoch'):\n",
    "            model.last_saved_epoch = 0\n",
    "        if ((time.time() - start_time) / (maximum_runtime * 60 / N_epochs_to_save)) > model.last_saved_epoch:\n",
    "            print('Saving model..')\n",
    "            config_sample['epoch_in_training'] = epoch\n",
    "            save_model(model, base_path, f'models_diff/prior_diff_real_checkpoint{add_name}_n_{i}_epoch_{model.last_saved_epoch}.cpkt',\n",
    "                           config_sample)\n",
    "            model.last_saved_epoch = model.last_saved_epoch + 1 # TODO: Rename to checkpoint\n",
    "    \n",
    "    model = get_model(config_sample\n",
    "                      , device\n",
    "                      , should_train=True\n",
    "                      , verbose=1\n",
    "                      , epoch_callback = save_callback)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df7905e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_config(config, indent=0):\n",
    "    sorted_config = dict(sorted(config.items(), key=lambda x: str(x[0])))\n",
    "    for key, value in sorted_config.items():\n",
    "        if isinstance(value, dict):\n",
    "            print(f\"{' ' * indent}{key}:\")\n",
    "            print_config(value, indent + 4)\n",
    "        else:\n",
    "            print(f\"{' ' * indent}{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c4dd5e",
   "metadata": {},
   "source": [
    "# Create Hyperparameters for Priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99ce58d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prior_config(config_type, causal_config = None, gp_config = None, bnn_config= None):\n",
    "    if config_type == 'causal':\n",
    "        return get_prior_config_causal(causal_config=causal_config)\n",
    "    elif config_type == 'gp':\n",
    "        return get_prior_config_gp(gp_config=gp_config)\n",
    "    elif config_type == 'bnn':\n",
    "        return get_prior_config_bnn(bnn_config=bnn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15fb5dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prior_config_causal( causal_config, max_features=100):\n",
    "    config_general = get_general_config(max_features, 50, eval_positions=[30])\n",
    "    config_general_real_world = {**config_general}\n",
    "\n",
    "    config_flexible_categorical = get_flexible_categorical_config(max_features)\n",
    "    config_flexible_categorical_real_world = {**config_flexible_categorical}\n",
    "    config_flexible_categorical_real_world[\n",
    "        'num_categorical_features_sampler_a'] = -1.0  # Categorical features disabled by default\n",
    "\n",
    "    config_gp = {}\n",
    "    config_mlp = {}\n",
    "\n",
    "    config_diff = get_diff_config(causal_config=causal_config)\n",
    "\n",
    "    config = {**config_general_real_world, **config_flexible_categorical_real_world, **config_diff, **config_gp,\n",
    "              **config_mlp}\n",
    "\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c0ac1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prior_config_gp(gp_config, max_features=100):\n",
    "    config_general = get_general_config(max_features, 50, eval_positions=[30])\n",
    "    config_general_real_world = {**config_general}\n",
    "    \n",
    "    config_flexible_categorical = get_flexible_categorical_config(max_features)\n",
    "    config_flexible_categorical_real_world = {**config_flexible_categorical}\n",
    "    \n",
    "    config_gp = {}\n",
    "\n",
    "    config_diff = get_diff_config(gp_config=gp_config)\n",
    "    \n",
    "    config = {**config_general_real_world, **\n",
    "              config_flexible_categorical_real_world, **config_diff, **config_gp}\n",
    "    config['differentiable_hyperparameters']['prior_bag_exp_weights_1'] = {'distribution': 'uniform', 'min': 0.0,\n",
    "                                                                           'max': .01}  # Never select MLP\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68ddc25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prior_config_bnn(bnn_config, max_features=100):\n",
    "    config_general = get_general_config(max_features, 50, eval_positions=[30])\n",
    "    config_general_real_world = {**config_general}\n",
    "\n",
    "    config_flexible_categorical = get_flexible_categorical_config(max_features)\n",
    "    config_flexible_categorical_real_world = {**config_flexible_categorical}\n",
    "\n",
    "    config_gp = {}\n",
    "    config_mlp = {}\n",
    "\n",
    "    config_diff = get_diff_config(bnn_config=bnn_config)\n",
    "\n",
    "    config = {**config_general_real_world, **config_flexible_categorical_real_world, **config_diff, **config_gp,\n",
    "              **config_mlp}\n",
    "\n",
    "    config['differentiable_hyperparameters']['prior_bag_exp_weights_1'] = {'distribution': 'uniform',\n",
    "                                                                           'min': 1000.0,\n",
    "                                                                           'max': 1001.0}  # Always select MLP\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15c8ee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_general_config(max_features, bptt, eval_positions=None):\n",
    "    \"\"\"\"\n",
    "    Returns the general PFN training hyperparameters.\n",
    "    \"\"\"\n",
    "    config_general = {\n",
    "        \"lr\": CSH.UniformFloatHyperparameter('lr', lower=0.0001, upper=0.00015, log=True),\n",
    "        \"dropout\": CSH.CategoricalHyperparameter('dropout', [0.0]),\n",
    "        # upper bound is -1\n",
    "        \"emsize\": CSH.CategoricalHyperparameter('emsize', [2 ** i for i in range(8, 9)]),\n",
    "        \"batch_size\": CSH.CategoricalHyperparameter('batch_size', [2 ** i for i in range(6, 8)]),\n",
    "        \"nlayers\": CSH.CategoricalHyperparameter('nlayers', [12]),\n",
    "        \"num_features\": max_features,\n",
    "        \"nhead\": CSH.CategoricalHyperparameter('nhead', [4]),\n",
    "        \"nhid_factor\": 2,\n",
    "        \"bptt\": bptt,\n",
    "        \"eval_positions\": None,\n",
    "        \"seq_len_used\": bptt,\n",
    "        # hp.choice('sampling', ['mixed', 'normal']), # uniform\n",
    "        \"sampling\": 'normal',\n",
    "        \"epochs\": 80,\n",
    "        \"num_steps\": 100,\n",
    "        \"verbose\": False,\n",
    "        \"mix_activations\": False,\n",
    "        \"pre_sample_causes\": True,\n",
    "        \"multiclass_type\": 'rank'\n",
    "    }\n",
    "\n",
    "    return config_general\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558947b0",
   "metadata": {},
   "source": [
    "## Causal Structural Model Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fcc7146",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_diff_causal(num_layers_max_alpha=2,\n",
    "                    num_layers_max_scale=3,\n",
    "                    prior_mlp_hidden_dim_max_alpha=3,\n",
    "                    prior_mlp_hidden_dim_max_scale=100,\n",
    "                    prior_mlp_dropout_prob_scale=0.6,\n",
    "                    prior_mlp_dropout_prob_min=0.1,\n",
    "                    prior_mlp_dropout_prob_max=5.0,\n",
    "                    noise_std_max_mean=0.3,\n",
    "                    noise_std_min_mean=0.0001, \n",
    "                    init_std_max_mean=10.0,\n",
    "                    init_std_min_mean=0.01,\n",
    "                    num_causes_max_alpha=3, \n",
    "                    num_causes_max_scale=7):\n",
    "    \"\"\"\"\n",
    "    Returns the configuration parameters for a differentiable wrapper around MLP / Causal mixture.\n",
    "    \"\"\"\n",
    "    diff_causal = {\n",
    "        # \"mix_activations\": {'distribution': 'meta_choice', 'choice_values': [True, False]},\n",
    "        # \"num_layers\": {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 6, 'min_mean': 1, 'round': True,\n",
    "        #               'lower_bound': 2},\n",
    "        \"num_layers\": {'distribution': 'meta_gamma',\n",
    "                       'max_alpha': num_layers_max_alpha,\n",
    "                       'max_scale': num_layers_max_scale,\n",
    "                       'round': True,\n",
    "                       'lower_bound': 2},\n",
    "        # Better beta?\n",
    "        # \"prior_mlp_hidden_dim\": {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 130, 'min_mean': 5,\n",
    "        #                         'round': True, 'lower_bound': 4},\n",
    "        \"prior_mlp_hidden_dim\": {'distribution': 'meta_gamma',\n",
    "                                 'max_alpha': prior_mlp_hidden_dim_max_alpha,\n",
    "                                 'max_scale': prior_mlp_hidden_dim_max_scale,\n",
    "                                 'round': True,\n",
    "                                 'lower_bound': 4},\n",
    "\n",
    "        \"prior_mlp_dropout_prob\": {'distribution':\n",
    "                                   'meta_beta',\n",
    "                                   'scale': prior_mlp_dropout_prob_scale,\n",
    "                                   'min': prior_mlp_dropout_prob_min,\n",
    "                                   'max': prior_mlp_dropout_prob_max},\n",
    "        # This mustn't be too high since activations get too large otherwise\n",
    "\n",
    "        \"noise_std\": {'distribution': 'meta_trunc_norm_log_scaled',\n",
    "                      'max_mean': noise_std_max_mean,\n",
    "                      'min_mean': noise_std_min_mean,\n",
    "                      'round': False,\n",
    "                      'lower_bound': 0.0},\n",
    "\n",
    "        \"init_std\": {'distribution': 'meta_trunc_norm_log_scaled',\n",
    "                     'max_mean': init_std_max_mean,\n",
    "                     'min_mean': init_std_min_mean,\n",
    "                     'round': False,\n",
    "                     'lower_bound': 0.0},\n",
    "\n",
    "        # \"num_causes\": {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 12, 'min_mean': 1, 'round': True,\n",
    "        #               'lower_bound': 1},\n",
    "        \"num_causes\": {'distribution': 'meta_gamma',\n",
    "                       'max_alpha': num_causes_max_alpha,\n",
    "                       'max_scale': num_causes_max_scale,\n",
    "                       'round': True,\n",
    "                       'lower_bound': 2},\n",
    "\n",
    "        \"is_causal\": {'distribution': 'meta_choice',\n",
    "                      'choice_values': [True, False]},\n",
    "\n",
    "        \"pre_sample_weights\": {'distribution': 'meta_choice',\n",
    "                               'choice_values': [True, False]},\n",
    "\n",
    "        \"y_is_effect\": {'distribution': 'meta_choice',\n",
    "                        'choice_values': [True, False]},\n",
    "\n",
    "        \"sampling\": {'distribution': 'meta_choice',\n",
    "                     'choice_values': ['normal', 'mixed']},\n",
    "\n",
    "        \"prior_mlp_activations\": {'distribution': 'meta_choice_mixed',\n",
    "                                  'choice_values': [torch.nn.Tanh, torch.nn.Identity, torch.nn.ReLU]},\n",
    "\n",
    "        \"block_wise_dropout\": {'distribution': 'meta_choice',\n",
    "                               'choice_values': [True, False]},\n",
    "\n",
    "        \"sort_features\": {'distribution': 'meta_choice',\n",
    "                          'choice_values': [True, False]},\n",
    "\n",
    "        \"in_clique\": {'distribution': 'meta_choice',\n",
    "                      'choice_values': [True, False]},\n",
    "\n",
    "        # 'pre_sample_causes': {'distribution': 'meta_choice', 'choice_values': [True, False]},\n",
    "    }\n",
    "\n",
    "    return diff_causal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06e751c",
   "metadata": {},
   "source": [
    "## Gaussian Process Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91e462dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_gp(os_max_mean=10,\n",
    "                os_min_mean=0.00001,\n",
    "                ls_max_mean=10, \n",
    "                ls_min_mean=0.00001, \n",
    "                noise_choices = [0.00001, 0.0001, 0.01]):\n",
    "    \"\"\"\"\n",
    "    Returns the configuration parameters for a differentiable wrapper around GP.\n",
    "    \"\"\"\n",
    "    diff_gp = {\n",
    "        'outputscale': {'distribution': 'meta_trunc_norm_log_scaled',\n",
    "                        'max_mean': os_max_mean,\n",
    "                        'min_mean': os_min_mean,\n",
    "                        'round': False,\n",
    "                        'lower_bound': 0},\n",
    "        'lengthscale': {'distribution': 'meta_trunc_norm_log_scaled',\n",
    "                        'max_mean': ls_max_mean,\n",
    "                        'min_mean': ls_min_mean,\n",
    "                        'round': False,\n",
    "                        'lower_bound': 0},\n",
    "        'noise': {'distribution': 'meta_choice',\n",
    "                  'choice_values': noise_choices}\n",
    "    }\n",
    "\n",
    "    return diff_gp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45693f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flexible_categorical_config(max_features):\n",
    "    \"\"\"\"\n",
    "    Returns the configuration parameters for the tabular multiclass wrapper.\n",
    "    \"\"\"\n",
    "    config_flexible_categorical = {\n",
    "        \"nan_prob_unknown_reason_reason_prior\": CSH.CategoricalHyperparameter('nan_prob_unknown_reason_reason_prior', [0.5]),\n",
    "        \"categorical_feature_p\": CSH.CategoricalHyperparameter('categorical_feature_p', [0.0, 0.1, 0.2]),\n",
    "        \"nan_prob_no_reason\": CSH.CategoricalHyperparameter('nan_prob_no_reason', [0.0, 0.1]),\n",
    "        \"nan_prob_unknown_reason\": CSH.CategoricalHyperparameter('nan_prob_unknown_reason', [0.0]),\n",
    "        \"nan_prob_a_reason\": CSH.CategoricalHyperparameter('nan_prob_a_reason', [0.0]),\n",
    "        # \"num_classes\": lambda : random.randint(2, 10), \"balanced\": False,\n",
    "        \"max_num_classes\": 2,\n",
    "        \"num_classes\": 2,\n",
    "        # NN\n",
    "        \"noise_type\": CSH.CategoricalHyperparameter('noise_type', [\"Gaussian\"]),\n",
    "        \"balanced\": True,\n",
    "        \"normalize_to_ranking\": CSH.CategoricalHyperparameter('normalize_to_ranking', [False]),\n",
    "        \"set_value_to_nan\": CSH.CategoricalHyperparameter('set_value_to_nan', [0.5, 0.2, 0.0]),\n",
    "        \"normalize_by_used_features\": True,\n",
    "        \"num_features_used\":\n",
    "            {'uniform_int_sampler_f(3,max_features)': uniform_int_sampler_f(\n",
    "                1, max_features)}\n",
    "        # hp.choice('conv_activation', [{'distribution': 'uniform', 'min': 2.0, 'max': 8.0}, None]),\n",
    "    }\n",
    "    return config_flexible_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08f6dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_diff_flex():\n",
    "    \"\"\"\"\n",
    "    Returns the configuration parameters for a differentiable wrapper around the tabular multiclass wrapper.\n",
    "    \"\"\"\n",
    "    diff_flex = {\n",
    "        # \"ordinal_pct\": {'distribution': 'uniform', 'min': 0.0, 'max': 0.5},\n",
    "        # \"num_categorical_features_sampler_a\": hp.choice('num_categorical_features_sampler_a',\n",
    "        #                                                 [{'distribution': 'uniform', 'min': 0.3, 'max': 0.9}, None]),\n",
    "        # \"num_categorical_features_sampler_b\": {'distribution': 'uniform', 'min': 0.3, 'max': 0.9},\n",
    "\n",
    "        # CSH.CategoricalHyperparameter('output_multiclass_ordered_p', [0.0, 0.1, 0.2]),\n",
    "        \"output_multiclass_ordered_p\": {'distribution': 'uniform', 'min': 0.0, 'max': 0.5},\n",
    "        \"multiclass_type\": {'distribution': 'meta_choice', 'choice_values': ['value', 'rank']},\n",
    "    }\n",
    "\n",
    "    return diff_flex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14836585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_prior_bag(dist_type=\"uniform\", weights_min=2.0, weights_max=10.0):\n",
    "    \"\"\"\"\n",
    "    Returns the configuration parameters for a GP and MLP / Causal mixture.\n",
    "    \"\"\"\n",
    "    diff_prior_bag = {\n",
    "        'prior_bag_exp_weights_1': {'distribution': dist_type, 'min': weights_min, 'max': weights_max},\n",
    "        # MLP Weight (Biased, since MLP works better, 1.0 is weight for prior number 0)\n",
    "    }\n",
    "\n",
    "    return diff_prior_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3ac6623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_config(prior_bag_config = None, causal_config=None, gp_config = None, flex_config = None):\n",
    "    \"\"\"\"\n",
    "    Returns the configuration parameters for a differentiable wrapper around GP and MLP / Causal mixture priors.\n",
    "    \"\"\"\n",
    "    if prior_bag_config == None:\n",
    "        diff_prior_bag = get_diff_prior_bag()\n",
    "    else: \n",
    "        diff_prior_bag = get_diff_prior_bag(dist_type=prior_bag_config[\"dist_type\"], \n",
    "                                            weights_min=prior_bag_config[\"weights_min\"],\n",
    "                                            weights_max=prior_bag_config[\"weights_max\"]) \n",
    "        \n",
    "    # --------------------------------------------------\n",
    "    if causal_config == None:\n",
    "        diff_causal = get_diff_causal()\n",
    "    else:\n",
    "        diff_causal = get_diff_causal(num_layers_max_alpha=causal_config[\"num_layers_max_alpha\"],\n",
    "                    num_layers_max_scale=causal_config[\"num_layers_max_scale\"],\n",
    "                    prior_mlp_hidden_dim_max_alpha=causal_config[\"prior_mlp_hidden_dim_max_alpha\"],\n",
    "                    prior_mlp_hidden_dim_max_scale=causal_config[\"prior_mlp_hidden_dim_max_scale\"],\n",
    "                    prior_mlp_dropout_prob_scale=causal_config[\"prior_mlp_dropout_prob_scale\"],\n",
    "                    prior_mlp_dropout_prob_min=causal_config[\"prior_mlp_dropout_prob_min\"],\n",
    "                    prior_mlp_dropout_prob_max=causal_config[\"prior_mlp_dropout_prob_max\"],\n",
    "                    noise_std_max_mean=causal_config[\"noise_std_max_mean\"],\n",
    "                    noise_std_min_mean=causal_config[\"noise_std_min_mean\"], \n",
    "                    init_std_max_mean=causal_config[\"init_std_max_mean\"],\n",
    "                    init_std_min_mean=causal_config[\"init_std_min_mean\"],\n",
    "                    num_causes_max_alpha=causal_config[\"num_causes_max_alpha\"], \n",
    "                    num_causes_max_scale=causal_config[\"num_causes_max_scale\"]) # todo\n",
    "        \n",
    "    # --------------------------------------------------\n",
    "    if gp_config == None:\n",
    "        diff_gp = get_diff_gp()\n",
    "    else: \n",
    "        diff_gp = get_diff_gp(os_max_mean= gp_config[\"os_max_mean\"],\n",
    "                            os_min_mean=gp_config[\"os_min_mean\"], \n",
    "                            ls_max_mean=gp_config[\"ls_max_mean\"], \n",
    "                            ls_min_mean=gp_config[\"ls_min_mean\"], \n",
    "                            noise_choices=gp_config[\"noise_choices\"])\n",
    "        \n",
    "    # --------------------------------------------------\n",
    "    if flex_config == None:\n",
    "        diff_flex = get_diff_flex()\n",
    "    else: \n",
    "        diff_flex = get_diff_flex() # todo\n",
    "        \n",
    "    # --------------------------------------------------\n",
    "    config_diff = {'differentiable_hyperparameters': {\n",
    "        **diff_prior_bag, **diff_causal, **diff_gp, **diff_flex}}\n",
    "\n",
    "    return config_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8141b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_config(config_type='causal',\n",
    "                  causal_config=None,\n",
    "                  gp_config=None,\n",
    "                  bnn_config=None, \n",
    "                  task_type='multiclass', \n",
    "                  longer=0): \n",
    "    config = get_prior_config(config_type=config_type, \n",
    "                              causal_config=causal_config,\n",
    "                              gp_config=gp_config,\n",
    "                              bnn_config= bnn_config) \n",
    "    \n",
    "    config['prior_type'], config['differentiable'], config['flexible'] = 'prior_bag', True, True\n",
    "    \n",
    "    model_string = ''\n",
    "    \n",
    "    config['epochs'] = 12000\n",
    "    config['recompute_attn'] = True\n",
    "\n",
    "    config['max_num_classes'] = 10\n",
    "    config['num_classes'] = uniform_int_sampler_f(2, config['max_num_classes'])\n",
    "    config['balanced'] = False\n",
    "    model_string = model_string + '_multiclass'\n",
    "    \n",
    "    model_string = model_string + '_'+datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "    \n",
    "    return config, model_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539d5232",
   "metadata": {},
   "source": [
    "# Sample Hyperparameters for Priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0e86cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_hps_in_nested(config):\n",
    "    \"\"\"\"\n",
    "    Returns a list of hyperparameters from a nested dict of hyperparameters.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(config, CSH.Hyperparameter):\n",
    "        return [config]\n",
    "    elif isinstance(config, dict):\n",
    "        result = []\n",
    "        for k, v in config.items():\n",
    "            result += list_all_hps_in_nested(v)\n",
    "        return result\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "264992ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_configspace_from_hierarchical(config):\n",
    "    cs = CS.ConfigurationSpace()\n",
    "    for hp in list_all_hps_in_nested(config):\n",
    "        cs.add_hyperparameter(hp)\n",
    "    return cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8db0897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_in_configsample(config, configsample):\n",
    "    # config is our dict that defines config distribution\n",
    "    # configsample is a CS.Configuration\n",
    "    hierarchical_configsample = deepcopy(config)\n",
    "    for k, v in config.items():\n",
    "        if isinstance(v, CSH.Hyperparameter):\n",
    "            hierarchical_configsample[k] = configsample[v.name]\n",
    "        elif isinstance(v, dict):\n",
    "            hierarchical_configsample[k] = fill_in_configsample(v, configsample)\n",
    "    return hierarchical_configsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b4e55f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hypers(config, sample_diff_hps=False):\n",
    "    \"\"\"\"\n",
    "    Samples a hyperparameter configuration from a sampleable configuration (can be used in HP search).\n",
    "    \"\"\"\n",
    "    if sample_diff_hps:\n",
    "        # I do a deepcopy here, such that the config stays the same and can still be used with diff. hps\n",
    "        config = deepcopy(config)\n",
    "        replace_differentiable_distributions(config)\n",
    "    cs = create_configspace_from_hierarchical(config)\n",
    "    cs_sample = cs.sample_configuration()\n",
    "    return fill_in_configsample(config, cs_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db69626f",
   "metadata": {},
   "source": [
    "## Start configuration creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bc1e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gp_config_meta():\n",
    "    ## Sathya\n",
    "    #result = {\"os_max_mean\": 6, \n",
    "    #            \"os_min_mean\":0.001, \n",
    "    #            \"ls_max_mean\":6,\n",
    "    #            \"ls_min_mean\":0.0001,\n",
    "    #            \"noise_choices\":[0.0001, 0.001, 0.1],\n",
    "    #            }\n",
    "    #\n",
    "    # # \n",
    "    #Magnus\n",
    "    results = {\"os_max_mean\": 10, \n",
    "                \"os_min_mean\":2, \n",
    "                \"ls_max_mean\":12,\n",
    "                \"ls_min_mean\":4,\n",
    "                \"noise_choices\":[0.0001, 0.0001, 0.001]}\n",
    "    # \n",
    "    #  \n",
    "    # Jack\n",
    "    # results = {\"os_max_mean\": 15, \n",
    "    #             \"os_min_mean\":0.0001, \n",
    "    #             \"ls_max_mean\":12,\n",
    "    #             \"ls_min_mean\":0.0001,\n",
    "    #             \"noise_choices\":[0.0001, 0.0001, 0.001, 0.01, 0.1],\n",
    "    #             \n",
    "    # }\n",
    "    #     \n",
    "    # Ali\n",
    "    # results = {\"os_max_mean\": 3, \n",
    "    #             \"os_min_mean\":0.0001, \n",
    "    #             \"ls_max_mean\":4,\n",
    "    #             \"ls_min_mean\":0.0001,\n",
    "    #             \"noise_choices\":[0.0001, 0.0001, 0.001, 0.01, 0.1],\n",
    "    #            \n",
    "    # }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91517dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_causal_config_meta(number_of_configs = 1):\n",
    "        \n",
    "        return {\"num_layers_max_alpha\":2,\n",
    "                    \"num_layers_max_scale\":3,\n",
    "                    \"prior_mlp_hidden_dim_max_alpha\":3,\n",
    "                    \"prior_mlp_hidden_dim_max_scale\":100,\n",
    "                    \"prior_mlp_dropout_prob_scale\":0.6,\n",
    "                    \"prior_mlp_dropout_prob_min\":0.1,\n",
    "                    \"prior_mlp_dropout_prob_max\":5.0,\n",
    "                    \"noise_std_max_mean\":0.3,\n",
    "                    \"noise_std_min_mean\":0.0001, \n",
    "                    \"init_std_max_mean\":10.0,\n",
    "                    \"init_std_min_mean\":0.01,\n",
    "                    \"num_causes_max_alpha\":3, \n",
    "                    \"num_causes_max_scale\":7}\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6519d310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "Using cpu:0 device\n",
      "---------------------------------------------\n",
      "{'batch_size': 1, 'eval_pos_seq_len_sampler': <function train.<locals>.eval_pos_seq_len_sampler at 0x16d5a0d30>, 'seq_len_maximum': 1152, 'device': 'cpu:0', 'num_features': 100, 'hyperparameters': {'lr': 0.00013772752559376022, 'dropout': 0.0, 'emsize': 512, 'batch_size': 1, 'nlayers': 12, 'num_features': 100, 'nhead': 4, 'nhid_factor': 2, 'bptt': 1152, 'eval_positions': None, 'seq_len_used': 50, 'sampling': 'normal', 'epochs': 400, 'num_steps': 1024, 'verbose': False, 'mix_activations': False, 'pre_sample_causes': True, 'multiclass_type': 'rank', 'nan_prob_unknown_reason_reason_prior': 0.5, 'categorical_feature_p': 0.2, 'nan_prob_no_reason': 0.0, 'nan_prob_unknown_reason': 0.0, 'nan_prob_a_reason': 0.0, 'max_num_classes': 10, 'num_classes': <function uniform_int_sampler_f.<locals>.<lambda> at 0x16d2a91f0>, 'noise_type': 'Gaussian', 'balanced': False, 'normalize_to_ranking': False, 'set_value_to_nan': 0.1, 'normalize_by_used_features': True, 'num_features_used': <function uniform_int_sampler_f.<locals>.<lambda> at 0x16d2a9280>, 'num_categorical_features_sampler_a': -1.0, 'differentiable_hyperparameters': {'distribution': 'uniform', 'min': 2.0, 'max': 10.0}, 'prior_type': 'prior_bag', 'differentiable': True, 'flexible': True, 'recompute_attn': True, 'bptt_extra_samples': None, 'output_multiclass_ordered_p': 0.0, 'multiclass_loss_type': 'nono', 'normalize_with_sqrt': False, 'new_mlp_per_example': True, 'prior_mlp_scale_weights_sqrt': True, 'batch_size_per_gp_sample': None, 'normalize_ignore_label_too': False, 'differentiable_hps_as_style': False, 'max_eval_pos': 1000, 'random_feature_rotation': True, 'rotate_normalized_labels': True, 'canonical_y_encoder': False, 'aggregate_k_gradients': 8, 'total_available_time_in_s': None, 'train_mixed_precision': True, 'efficient_eval_masking': True, 'prior_bag_get_batch': (<function get_model.<locals>.make_get_batch.<locals>.new_get_batch at 0x16d5a0a60>, <function get_model.<locals>.make_get_batch.<locals>.new_get_batch at 0x16d5a0af0>), 'prior_bag_exp_weights_1': 2.0, 'normalize_labels': True, 'check_is_compatible': True}, 'batch_size_per_gp_sample': None, 'get_batch': <function get_model.<locals>.make_get_batch.<locals>.new_get_batch at 0x16d5a0b80>, 'differentiable_hyperparameters': {'prior_bag_exp_weights_1': {'distribution': 'uniform', 'min': 2.0, 'max': 10.0}, 'num_layers': {'distribution': 'meta_gamma', 'max_alpha': 2, 'max_scale': 3, 'round': True, 'lower_bound': 2}, 'prior_mlp_hidden_dim': {'distribution': 'meta_gamma', 'max_alpha': 3, 'max_scale': 100, 'round': True, 'lower_bound': 4}, 'prior_mlp_dropout_prob': {'distribution': 'meta_beta', 'scale': 0.6, 'min': 0.1, 'max': 5.0}, 'noise_std': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 0.3, 'min_mean': 0.0001, 'round': False, 'lower_bound': 0.0}, 'init_std': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 10.0, 'min_mean': 0.01, 'round': False, 'lower_bound': 0.0}, 'num_causes': {'distribution': 'meta_gamma', 'max_alpha': 3, 'max_scale': 7, 'round': True, 'lower_bound': 2}, 'is_causal': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'pre_sample_weights': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'y_is_effect': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'prior_mlp_activations': {'distribution': 'meta_choice_mixed', 'choice_values': [<class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.ReLU'>]}, 'block_wise_dropout': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'sort_features': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'in_clique': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'outputscale': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 10, 'min_mean': 1e-05, 'round': False, 'lower_bound': 0}, 'lengthscale': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 10, 'min_mean': 1e-05, 'round': False, 'lower_bound': 0}, 'noise': {'distribution': 'meta_choice', 'choice_values': [1e-05, 0.0001, 0.01]}}}\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m: \n\u001b[1;32m     55\u001b[0m     model \u001b[38;5;241m=\u001b[39m get_model(config_sample, device, should_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m     \u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbaseline_model_causal_1.cpkt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_sample\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/MSGPFN/tabpfn/scripts/model_builder.py:29\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, path, filename, config_sample)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#if 'num_features_used' in config_sample:\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#    del config_sample['num_features_used']\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#config_sample['num_classes_as_str'] = str(config_sample['num_classes'])\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#del config_sample['num_classes']\u001b[39;00m\n\u001b[1;32m     27\u001b[0m config_sample \u001b[38;5;241m=\u001b[39m make_serializable(config_sample)\n\u001b[0;32m---> 29\u001b[0m torch\u001b[38;5;241m.\u001b[39msave((\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m(), \u001b[38;5;28;01mNone\u001b[39;00m, config_sample), os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, filename))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'state_dict'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "causal_config = sample_causal_config_meta()  \n",
    "bnn_config = None\n",
    "gp_config = None\n",
    "\n",
    "\n",
    "\n",
    "config, model_string = reload_config(config_type='causal',\n",
    "                                     longer=1,\n",
    "                                     causal_config=causal_config, \n",
    "                                     gp_config=gp_config, \n",
    "                                     bnn_config = bnn_config)\n",
    "config['bptt_extra_samples'] = None\n",
    "# diff\n",
    "config['output_multiclass_ordered_p'] = 0.\n",
    "del config['differentiable_hyperparameters']['output_multiclass_ordered_p']\n",
    "config['multiclass_type'] = 'rank'\n",
    "del config['differentiable_hyperparameters']['multiclass_type']\n",
    "config['sampling'] = 'normal' # vielleicht schlecht?\n",
    "del config['differentiable_hyperparameters']['sampling']\n",
    "config['pre_sample_causes'] = True\n",
    "# end diff\n",
    "config['multiclass_loss_type'] = 'nono' # 'compatible'\n",
    "config['normalize_to_ranking'] = False # False\n",
    "config['categorical_feature_p'] = .2 # diff: .0\n",
    "# turn this back on in a random search!?\n",
    "config['nan_prob_no_reason'] = .0\n",
    "config['nan_prob_unknown_reason'] = .0 # diff: .0\n",
    "config['set_value_to_nan'] = .1 # diff: 1.\n",
    "config['normalize_with_sqrt'] = False\n",
    "config['new_mlp_per_example'] = True\n",
    "config['prior_mlp_scale_weights_sqrt'] = True\n",
    "config['batch_size_per_gp_sample'] = None\n",
    "config['normalize_ignore_label_too'] = False\n",
    "config['differentiable_hps_as_style'] = False\n",
    "config['max_eval_pos'] = 1000\n",
    "config['random_feature_rotation'] = True\n",
    "config['rotate_normalized_labels'] = True\n",
    "config[\"mix_activations\"] = False # False heisst eig True\n",
    "config['emsize'] = 512\n",
    "config['nhead'] = config['emsize'] // 128\n",
    "config['bptt'] = 1024+128\n",
    "config['canonical_y_encoder'] = False\n",
    "config['aggregate_k_gradients'] = 8\n",
    "config['batch_size'] = 8*config['aggregate_k_gradients']\n",
    "config['num_steps'] = 1024//config['aggregate_k_gradients']\n",
    "config['epochs'] = 400\n",
    "config['total_available_time_in_s'] = None #60*60*22 # 22 hours for some safety...\n",
    "config['train_mixed_precision'] = True\n",
    "config['efficient_eval_masking'] = True\n",
    "#print_config(config)\n",
    "config_sample = evaluate_hypers(config)\n",
    "config_sample['batch_size'] = 4\n",
    "# print_config(config_sample)\n",
    "if True: \n",
    "    model = get_model(config_sample, device, should_train=False, verbose=0)\n",
    "    save_model(model[2], base_path, f'baseline_model_causal_1.cpkt', config_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6ddb86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabpfn",
   "language": "python",
   "name": "tabpfn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
