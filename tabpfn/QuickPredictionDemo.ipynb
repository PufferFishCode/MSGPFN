{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to use TabPFN for tabular prediction with a scikit learn wrapper.\n",
    "\n",
    "classifier = TabPFNClassifier(device='cpu')\n",
    "classifier.fit(train_xs, train_ys)\n",
    "prediction_ = classifier.predict(test_xs)\n",
    "\n",
    "The fit function does not perform any computations, but only saves the training data. Computations are only done at inference time, when calling predict.\n",
    "Note that the presaved models were trained for up to 100 features, 10 classes and 1000 samples. While the model does not have a hard bound on the number of samples, the features and classes are restricted and larger sizes lead to an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from scripts.model_builder import get_default_spec, save_model, load_model_only_inference\n",
    "from scripts.transformer_prediction_interface import transformer_predict, get_params_from_config, TabPFNClassifier\n",
    "from scripts.differentiable_pfn_evaluation import eval_model, eval_model_range\n",
    "\n",
    "from datasets import load_openml_list, open_cc_dids, open_cc_valid_dids, test_dids_classification\n",
    "\n",
    "from scripts import tabular_metrics\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets: 30\n",
      "Loading balance-scale 11 ..\n",
      "Loading mfeat-fourier 14 ..\n",
      "Loading breast-w 15 ..\n",
      "Loading mfeat-karhunen 16 ..\n",
      "Loading mfeat-morphological 18 ..\n",
      "Loading mfeat-zernike 22 ..\n",
      "Loading cmc 23 ..\n",
      "Loading credit-approval 29 ..\n",
      "Loading credit-g 31 ..\n",
      "Loading diabetes 37 ..\n",
      "Loading tic-tac-toe 50 ..\n",
      "Loading vehicle 54 ..\n",
      "Loading eucalyptus 188 ..\n",
      "Loading analcatdata_authorship 458 ..\n",
      "Loading analcatdata_dmft 469 ..\n",
      "Loading pc4 1049 ..\n",
      "Loading pc3 1050 ..\n",
      "Loading kc2 1063 ..\n",
      "Loading pc1 1068 ..\n",
      "Loading banknote-authentication 1462 ..\n",
      "Loading blood-transfusion-service-center 1464 ..\n",
      "Loading ilpd 1480 ..\n",
      "Loading qsar-biodeg 1494 ..\n",
      "Loading wdbc 1510 ..\n",
      "Loading cylinder-bands 6332 ..\n",
      "Loading dresses-sales 23381 ..\n",
      "Loading MiceProtein 40966 ..\n",
      "Loading car 40975 ..\n",
      "Loading steel-plates-fault 40982 ..\n",
      "Loading climate-model-simulation-crashes 40994 ..\n",
      "Number of datasets: 150\n",
      "Loading breast-cancer 13 ..\n",
      "Loading colic 25 ..\n",
      "Loading dermatology 35 ..\n",
      "Loading sonar 40 ..\n",
      "Loading glass 41 ..\n",
      "Loading haberman 43 ..\n",
      "Loading tae 48 ..\n",
      "Loading heart-c 49 ..\n",
      "Loading heart-h 51 ..\n",
      "Loading heart-statlog 53 ..\n",
      "Loading hepatitis 55 ..\n",
      "Loading vote 56 ..\n",
      "Loading ionosphere 59 ..\n",
      "Loading iris 61 ..\n",
      "Loading wine 187 ..\n",
      "Loading flags 285 ..\n",
      "Loading hayes-roth 329 ..\n",
      "Loading monks-problems-1 333 ..\n",
      "Loading monks-problems-2 334 ..\n",
      "Loading monks-problems-3 335 ..\n",
      "Loading SPECT 336 ..\n",
      "Loading SPECTF 337 ..\n",
      "Loading grub-damage 338 ..\n",
      "Loading synthetic_control 377 ..\n",
      "Loading prnn_crabs 446 ..\n",
      "Loading analcatdata_lawsuit 450 ..\n",
      "Loading irish 451 ..\n",
      "Loading analcatdata_broadwaymult 452 ..\n",
      "Loading analcatdata_reviewer 460 ..\n",
      "Loading backache 463 ..\n",
      "Loading prnn_synth 464 ..\n",
      "Loading schizo 466 ..\n",
      "Loading profb 470 ..\n",
      "Loading analcatdata_germangss 475 ..\n",
      "Loading biomed 481 ..\n",
      "Loading rmftsa_sleepdata 679 ..\n",
      "Loading diggle_table_a2 694 ..\n",
      "Loading rmftsa_ladata 717 ..\n",
      "Loading pwLinear 721 ..\n",
      "Loading analcatdata_vineyard 724 ..\n",
      "Loading machine_cpu 733 ..\n",
      "Loading pharynx 738 ..\n",
      "Loading auto_price 745 ..\n",
      "Loading servo 747 ..\n",
      "Loading analcatdata_wildcat 748 ..\n",
      "Loading pm10 750 ..\n",
      "Loading wisconsin 753 ..\n",
      "Loading autoPrice 756 ..\n",
      "Loading meta 757 ..\n",
      "Loading analcatdata_apnea3 764 ..\n",
      "Loading analcatdata_apnea2 765 ..\n",
      "Loading analcatdata_apnea1 767 ..\n",
      "Loading disclosure_x_bias 774 ..\n",
      "Loading bodyfat 778 ..\n",
      "Loading cleveland 786 ..\n",
      "Loading triazines 788 ..\n",
      "Loading disclosure_x_tampered 795 ..\n",
      "Loading cpu 796 ..\n",
      "Loading cholesterol 798 ..\n",
      "Loading chscase_funds 801 ..\n",
      "Loading pbcseq 802 ..\n",
      "Loading pbc 810 ..\n",
      "Loading rmftsa_ctoarrivals 811 ..\n",
      "Loading chscase_vine2 814 ..\n",
      "Loading chatfield_4 820 ..\n",
      "Loading boston_corrected 825 ..\n",
      "Loading sensory 826 ..\n",
      "Loading disclosure_x_noise 827 ..\n",
      "Loading autoMpg 831 ..\n",
      "Loading kdd_el_nino-small 839 ..\n",
      "Loading autoHorse 840 ..\n",
      "Loading stock 841 ..\n",
      "Loading breastTumor 844 ..\n",
      "Loading analcatdata_gsssexsurvey 852 ..\n",
      "Loading boston 853 ..\n",
      "Loading fishcatch 854 ..\n",
      "Loading vinnie 860 ..\n",
      "Loading mu284 880 ..\n",
      "Loading no2 886 ..\n",
      "Loading chscase_geyser1 895 ..\n",
      "Loading chscase_census6 900 ..\n",
      "Loading chscase_census5 906 ..\n",
      "Loading chscase_census4 907 ..\n",
      "Loading chscase_census3 908 ..\n",
      "Loading chscase_census2 909 ..\n",
      "Loading plasma_retinol 915 ..\n",
      "Loading visualizing_galaxy 925 ..\n",
      "Loading colleges_usnews 930 ..\n",
      "Loading disclosure_z 931 ..\n",
      "Loading socmob 934 ..\n",
      "Loading chscase_whale 939 ..\n",
      "Loading water-treatment 940 ..\n",
      "Loading lowbwt 941 ..\n",
      "Loading arsenic-female-bladder 949 ..\n",
      "Loading analcatdata_halloffame 966 ..\n",
      "Loading analcatdata_birthday 968 ..\n",
      "Loading analcatdata_draft 984 ..\n",
      "Loading collins 987 ..\n",
      "Loading prnn_fglass 996 ..\n",
      "Loading jEdit_4.2_4.3 1048 ..\n",
      "Loading mc2 1054 ..\n",
      "Loading mw1 1071 ..\n",
      "Loading jEdit_4.0_4.2 1073 ..\n",
      "Loading PopularKids 1100 ..\n",
      "Loading teachingAssistant 1115 ..\n",
      "Loading lungcancer_GSE31210 1412 ..\n",
      "Loading MegaWatt1 1442 ..\n",
      "Loading PizzaCutter1 1443 ..\n",
      "Loading PizzaCutter3 1444 ..\n",
      "Loading CostaMadre1 1446 ..\n",
      "Loading CastMetal1 1447 ..\n",
      "Loading KnuggetChase3 1448 ..\n",
      "Loading PieChart1 1451 ..\n",
      "Loading PieChart3 1453 ..\n",
      "Loading parkinsons 1488 ..\n",
      "Loading planning-relax 1490 ..\n",
      "Loading qualitative-bankruptcy 1495 ..\n",
      "Loading sa-heart 1498 ..\n",
      "Loading seeds 1499 ..\n",
      "Loading thoracic-surgery 1506 ..\n",
      "Loading user-knowledge 1508 ..\n",
      "Loading wholesale-customers 1511 ..\n",
      "Loading heart-long-beach 1512 ..\n",
      "Loading robot-failures-lp5 1520 ..\n",
      "Loading vertebra-column 1523 ..\n",
      "Loading Smartphone-Based_Recognition_of_Human_Activities 4153 ..\n",
      "Loading breast-cancer-dropped-missing-attributes-values 23499 ..\n",
      "Loading LED-display-domain-7digit 40496 ..\n",
      "Loading GAMETES_Epistasis_2-Way_20atts_0.1H_EDM-1_1 40646 ..\n",
      "Loading calendarDOW 40663 ..\n",
      "Loading corral 40669 ..\n",
      "Loading mofn-3-7-10 40680 ..\n",
      "Loading thyroid-new 40682 ..\n",
      "Loading solar-flare 40686 ..\n",
      "Loading threeOf9 40690 ..\n",
      "Loading xd6 40693 ..\n",
      "Loading tokyo1 40705 ..\n",
      "Loading parity5_plus_5 40706 ..\n",
      "Loading cleve 40710 ..\n",
      "Loading cleveland-nominal 40711 ..\n",
      "Loading Australian 40981 ..\n",
      "Loading DiabeticMellitus 41430 ..\n",
      "Loading conference_attendance 41538 ..\n",
      "Loading CPMP-2015-runtime-classification 41919 ..\n",
      "Loading TuningSVMs 41976 ..\n",
      "Loading regime_alimentaire 42172 ..\n",
      "Loading iris-example 42261 ..\n",
      "Loading Touch2 42544 ..\n",
      "Loading penguins 42585 ..\n",
      "Loading titanic 42638 ..\n"
     ]
    }
   ],
   "source": [
    "max_samples = 10000\n",
    "bptt = 10000\n",
    "\n",
    "cc_test_datasets_multiclass, cc_test_datasets_multiclass_df = load_openml_list(open_cc_dids, multiclass=True, shuffled=True, filter_for_nan=False, max_samples = max_samples, num_feats=100, return_capped=True)\n",
    "cc_valid_datasets_multiclass, cc_valid_datasets_multiclass_df = load_openml_list(open_cc_valid_dids, multiclass=True, shuffled=True, filter_for_nan=False, max_samples = max_samples, num_feats=100, return_capped=True)\n",
    "\n",
    "# Loading longer OpenML Datasets for generalization experiments (optional)\n",
    "# test_datasets_multiclass, test_datasets_multiclass_df = load_openml_list(test_dids_classification, multiclass=True, shuffled=True, filter_for_nan=False, max_samples = 10000, num_feats=100, return_capped=True)\n",
    "\n",
    "random.seed(0)\n",
    "random.shuffle(cc_valid_datasets_multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(selector, task_type, suite='cc'):\n",
    "    if task_type == 'binary':\n",
    "        ds = valid_datasets_binary if selector == 'valid' else test_datasets_binary\n",
    "    else:\n",
    "        if suite == 'openml':\n",
    "            ds = valid_datasets_multiclass if selector == 'valid' else test_datasets_multiclass\n",
    "        elif suite == 'cc':\n",
    "            ds = cc_valid_datasets_multiclass if selector == 'valid' else cc_test_datasets_multiclass\n",
    "        else:\n",
    "            raise Exception(\"Unknown suite\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_string, longer, task_type = '', 1, 'multiclass'\n",
    "eval_positions = [1000]\n",
    "bptt = 2000\n",
    "    \n",
    "test_datasets, valid_datasets = get_datasets('test', task_type, suite='cc'), get_datasets('valid', task_type, suite='cc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Run on a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'balance-scale'),\n",
       " (1, 'mfeat-fourier'),\n",
       " (2, 'breast-w'),\n",
       " (3, 'mfeat-karhunen'),\n",
       " (4, 'mfeat-morphological'),\n",
       " (5, 'mfeat-zernike'),\n",
       " (6, 'cmc'),\n",
       " (7, 'credit-approval'),\n",
       " (8, 'credit-g'),\n",
       " (9, 'diabetes'),\n",
       " (10, 'tic-tac-toe'),\n",
       " (11, 'vehicle'),\n",
       " (12, 'eucalyptus'),\n",
       " (13, 'analcatdata_authorship'),\n",
       " (14, 'analcatdata_dmft'),\n",
       " (15, 'pc4'),\n",
       " (16, 'pc3'),\n",
       " (17, 'kc2'),\n",
       " (18, 'pc1'),\n",
       " (19, 'banknote-authentication'),\n",
       " (20, 'blood-transfusion-service-center'),\n",
       " (21, 'ilpd'),\n",
       " (22, 'qsar-biodeg'),\n",
       " (23, 'wdbc'),\n",
       " (24, 'cylinder-bands'),\n",
       " (25, 'dresses-sales'),\n",
       " (26, 'MiceProtein'),\n",
       " (27, 'car'),\n",
       " (28, 'steel-plates-fault'),\n",
       " (29, 'climate-model-simulation-crashes')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, test_datasets[i][0]) for i in range(len(test_datasets))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation dataset name: balance-scale shape torch.Size([625, 4])\n"
     ]
    }
   ],
   "source": [
    "evaluation_dataset_index = 0 # Index of the dataset to predict\n",
    "ds = test_datasets[evaluation_dataset_index]\n",
    "print(f'Evaluation dataset name: {ds[0]} shape {ds[1].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = ds[1].clone(), ds[2].clone()\n",
    "eval_position = xs.shape[0] // 2\n",
    "train_xs, train_ys = xs[0:eval_position], ys[0:eval_position]\n",
    "test_xs, test_ys = xs[eval_position:], ys[eval_position:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have to download the TabPFN, as there is no checkpoint at  /Users/magnus/Developer/MSGPFN/tabpfn/models_diff/prior_diff_real_checkpoint_n_0_epoch_100.cpkt\n",
      "It has about 100MB, so this might take a moment.\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    }
   ],
   "source": [
    "classifier = TabPFNClassifier(device='cpu')\n",
    "classifier.fit(train_xs, train_ys)\n",
    "prediction_ = classifier.predict_proba(test_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('AUC', 0.9993487936075042, 'Cross Entropy', 0.571309506893158)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc, ce = tabular_metrics.auc_metric(test_ys, prediction_), tabular_metrics.cross_entropy(test_ys, prediction_)\n",
    "'AUC', float(roc), 'Cross Entropy', float(ce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Run on all datasets\n",
    "This section runs a differentiable hyperparameter tuning run and saves the results to a results file, which can be inserted in TabularEval.ipynb to compare to other baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Running eval dataset with final params (no gradients)..\n",
      "Running with 32 ensemble_configurations\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m eval_addition \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_run\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[43meval_model_range\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                          \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_datasets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;66;43;03m#cc_valid_datasets_multiclass\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m                          \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_datasets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcc_test_datasets_multiclass\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                          \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_datasets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                          \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_positions_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_positions\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                          \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbptt_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbptt\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                          \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_string\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                          \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                          \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselection_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                          \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_grad_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                          \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_addition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_addition\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                          \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_ensemble_configurations_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                          \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#range(0, 10)\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/MSGPFN/tabpfn/scripts/differentiable_pfn_evaluation.py:23\u001b[0m, in \u001b[0;36meval_model_range\u001b[0;34m(i_range, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_model_range\u001b[39m(i_range, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m i_range:\n\u001b[0;32m---> 23\u001b[0m         \u001b[43meval_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/MSGPFN/tabpfn/scripts/differentiable_pfn_evaluation.py:62\u001b[0m, in \u001b[0;36meval_model\u001b[0;34m(i, e, valid_datasets, test_datasets, train_datasets, add_name, base_path, eval_positions_valid, eval_positions_test, bptt_valid, bptt_test, device, eval_addition, differentiable, **extra_tuning_args)\u001b[0m\n\u001b[1;32m     59\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(get_params_from_config(c))\n\u001b[1;32m     61\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 62\u001b[0m metrics, metrics_valid, style, temperature, optimization_route \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_point_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m                                                                                                   \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_tuning_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvaluation time: \u001b[39m\u001b[38;5;124m'\u001b[39m, time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_file)\n",
      "File \u001b[0;32m~/Developer/MSGPFN/tabpfn/scripts/differentiable_pfn_evaluation.py:153\u001b[0m, in \u001b[0;36mevaluate_point_model\u001b[0;34m(model, valid_datasets, test_datasets, train_datasets, eval_positions_test, bptt_final, device, selection_metric, final_splits, N_ensemble_configurations_list, bptt, eval_positions, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     result_valid \u001b[38;5;241m=\u001b[39m eval_step(valid_datasets, \u001b[38;5;28;01mNone\u001b[39;00m, softmax_temperature\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    147\u001b[0m                              , return_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, eval_positions\u001b[38;5;241m=\u001b[39meval_positions_test,\n\u001b[1;32m    148\u001b[0m                              bptt\u001b[38;5;241m=\u001b[39mbptt_final, model\u001b[38;5;241m=\u001b[39mmodel[\u001b[38;5;241m2\u001b[39m], device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m    149\u001b[0m                              , selection_metric\u001b[38;5;241m=\u001b[39mselection_metric, evaluation_metric\u001b[38;5;241m=\u001b[39mevaluation_metric,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result_test, result_valid\n\u001b[0;32m--> 153\u001b[0m result_test, result_valid \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result_test, result_valid, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/MSGPFN/tabpfn/scripts/differentiable_pfn_evaluation.py:138\u001b[0m, in \u001b[0;36mevaluate_point_model.<locals>.final_evaluation\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m     splits \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m final_splits:\n\u001b[0;32m--> 138\u001b[0m         splits \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[43meval_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_datasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msoftmax_temperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m                             \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_positions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_positions_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mbptt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbptt_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m                             \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselection_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselection_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluation_metric\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m                             \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    143\u001b[0m     result_test \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [splits]\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning valid dataset with final params (no gradients)..\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Developer/MSGPFN/tabpfn/scripts/differentiable_pfn_evaluation.py:174\u001b[0m, in \u001b[0;36meval_step\u001b[0;34m(ds, used_style, selection_metric, evaluation_metric, eval_positions, return_tensor, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 174\u001b[0m         r \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m calculate_score_per_method(selection_metric, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselect\u001b[39m\u001b[38;5;124m'\u001b[39m, r, ds, eval_positions, aggregator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    177\u001b[0m calculate_score_per_method(evaluation_metric, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m'\u001b[39m, r, ds, eval_positions, aggregator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Developer/MSGPFN/tabpfn/scripts/differentiable_pfn_evaluation.py:159\u001b[0m, in \u001b[0;36meval_step.<locals>.step\u001b[0;34m()\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m():\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtransformer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m    161\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    162\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mused_style\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_positions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_positions\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_used\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselection_metric\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    166\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_interfix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    167\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    168\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tabpfn/scripts/tabular_evaluation.py:117\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(datasets, bptt, eval_positions, metric_used, model, device, verbose, return_tensor, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m eval_position_real \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(dataset_bptt \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m eval_position \u001b[38;5;241m>\u001b[39m dataset_bptt \u001b[38;5;28;01melse\u001b[39;00m eval_position\n\u001b[1;32m    115\u001b[0m eval_position_bptt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(eval_position_real \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2.0\u001b[39m)\n\u001b[0;32m--> 117\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m            \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m            \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_feats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcategorical_feats\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m            \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbptt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meval_position_bptt\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m            \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_name\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m            \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_position\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meval_position_real\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m            \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_used\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetric_used\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m                      \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m            \u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExecution failed\u001b[39m\u001b[38;5;124m'\u001b[39m, ds_name)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tabpfn/scripts/tabular_evaluation.py:285\u001b[0m, in \u001b[0;36mevaluate_position\u001b[0;34m(X, y, categorical_feats, model, bptt, eval_position, overwrite, save, base_path, path_interfix, method, ds_name, fetch_only, max_time, split_number, metric_used, device, per_step_normalization, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, nn\u001b[38;5;241m.\u001b[39mModule): \u001b[38;5;66;03m# Two separate predict interfaces for transformer and baselines\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m     outputs, best_configs \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_xs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_ys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_position\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_used\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_used\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_feats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feats\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    288\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextend_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m                                                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    292\u001b[0m     _, outputs, best_configs \u001b[38;5;241m=\u001b[39m baseline_predict(model, eval_xs, eval_ys, categorical_feats\n\u001b[1;32m    293\u001b[0m                                                 , eval_pos\u001b[38;5;241m=\u001b[39meval_position\n\u001b[1;32m    294\u001b[0m                                                 , device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m    295\u001b[0m                                                 , max_time\u001b[38;5;241m=\u001b[39mmax_time, metric_used\u001b[38;5;241m=\u001b[39mmetric_used, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tabpfn/scripts/transformer_prediction_interface.py:517\u001b[0m, in \u001b[0;36mtransformer_predict\u001b[0;34m(model, eval_xs, eval_ys, eval_position, device, max_features, style, inference_mode, num_classes, extend_features, normalize_with_test, normalize_to_ranking, softmax_temperature, multiclass_decoder, preprocess_transform, categorical_feats, feature_shift_decoder, N_ensemble_configurations, batch_size_inference, differentiable_hps_as_style, average_logits, fp16_inference, normalize_with_sqrt, seed, no_grad, return_logits, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    515\u001b[0m                         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 517\u001b[0m     output_batch \u001b[38;5;241m=\u001b[39m \u001b[43mcheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msoftmax_temperature_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39mfp16_inference):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/torch/utils/checkpoint.py:211\u001b[0m, in \u001b[0;36mcheckpoint\u001b[0;34m(function, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected keyword arguments: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(arg \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m kwargs))\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCheckpointFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/torch/utils/checkpoint.py:90\u001b[0m, in \u001b[0;36mCheckpointFunction.forward\u001b[0;34m(ctx, run_function, preserve_rng_state, *args)\u001b[0m\n\u001b[1;32m     87\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(\u001b[38;5;241m*\u001b[39mtensor_inputs)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 90\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mrun_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tabpfn/scripts/transformer_prediction_interface.py:353\u001b[0m, in \u001b[0;36mtransformer_predict.<locals>.predict\u001b[0;34m(eval_xs, eval_ys, used_style, softmax_temperature, return_logits)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m inference_mode_call:\n\u001b[1;32m    352\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 353\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43mused_style\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_xs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mused_style\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_xs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_ys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m            \u001b[49m\u001b[43msingle_eval_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_position\u001b[49m\u001b[43m)\u001b[49m[:, :, \u001b[38;5;241m0\u001b[39m:num_classes]\n\u001b[1;32m    357\u001b[0m     output \u001b[38;5;241m=\u001b[39m output[:, :, \u001b[38;5;241m0\u001b[39m:num_classes] \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(softmax_temperature)\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_logits:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tabpfn/transformer.py:141\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[0;34m(self, src, src_mask, single_eval_pos)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder(src)\n\u001b[0;32m--> 141\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(output)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output[single_eval_pos\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlen\u001b[39m(style_src)\u001b[38;5;241m+\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_att_embeddings\u001b[38;5;241m.\u001b[39mnum_embeddings \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_att_embeddings \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m):]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tabpfn/transformer.py:227\u001b[0m, in \u001b[0;36mTransformerEncoderDiffInit.forward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    224\u001b[0m output \u001b[38;5;241m=\u001b[39m src\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 227\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(output)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/tabpfn/layer.py:125\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     src_ \u001b[38;5;241m=\u001b[39m src\n\u001b[0;32m--> 125\u001b[0m src2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m    126\u001b[0m src \u001b[38;5;241m=\u001b[39m src \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(src2)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_norm:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/torch/nn/functional.py:1555\u001b[0m, in \u001b[0;36mgelu\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m   1553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m   1554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(gelu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1555\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eval_positions=[1000]\n",
    "bptt=2000\n",
    "\n",
    "N_models = 3\n",
    "models_per_block = 1\n",
    "\n",
    "eval_addition = 'user_run'\n",
    "device = 'cpu'\n",
    "\n",
    "eval_model_range(i_range=[0], e=-1\n",
    "                          , valid_datasets=[]#cc_valid_datasets_multiclass\n",
    "                          , test_datasets=cc_test_datasets_multiclass\n",
    "                          , train_datasets=[]\n",
    "                          , eval_positions_test=eval_positions\n",
    "                          , bptt_test=bptt\n",
    "                          , add_name=model_string\n",
    "                          , base_path=base_path\n",
    "                          , selection_metric='auc'\n",
    "                          , best_grad_steps=0\n",
    "                          , eval_addition=eval_addition\n",
    "                          , N_ensemble_configurations_list = [32]\n",
    "                          , device=device)#range(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2, 5, 4, 3, 6, 1]],\n",
      "\n",
      "        [[4, 7, 6, 5, 8, 3]]])\n"
     ]
    }
   ],
   "source": [
    "# --------------------- permutate along embed dim --------------------- \n",
    "def permutate_embed_dim(input_tensor):\n",
    "    batch_size, sequence_dim, embed_dim = input_tensor.size()\n",
    "\n",
    "    # Generate random permutation\n",
    "    perm = torch.randperm(embed_dim)\n",
    "\n",
    "    # Expand permutation tensor\n",
    "    perm = perm.unsqueeze(0).unsqueeze(1).expand(batch_size, sequence_dim, embed_dim)\n",
    "\n",
    "    # Apply permutation to input tensor\n",
    "    input_tensor_permuted = input_tensor.gather(2, perm)\n",
    "\n",
    "    return input_tensor_permuted\n",
    "# --------------------- permutate along embed dim --------------------- \n",
    "# --------------------- check permutation --------------------- \n",
    "test = torch.tensor([[[1,2,3,4,5,6]],[[3,4,5,6,7,8]]])\n",
    "test.shape\n",
    "print(permutate_embed_dim(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run generalization experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading longer OpenML Datasets for generalization experiments (optional)\n",
    "test_datasets_multiclass, test_datasets_multiclass_df = load_openml_list(test_dids_classification, multiclass=True, shuffled=True, filter_for_nan=False, max_samples = 10000, num_feats=100, return_capped=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datasets_longer_generalization = [ds for ds in test_datasets_multiclass if ds[1].shape[0] >= 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gen(classifier_key, split):\n",
    "    ces = []\n",
    "    for k in tqdm(range(0, len(test_datasets_longer_generalization))):\n",
    "        x, y = test_datasets_longer_generalization[k][1], test_datasets_longer_generalization[k][2].numpy()\n",
    "        x = normalize_data(x).numpy()\n",
    "        x[np.isnan(x)] = 0.0\n",
    "        print(x.shape[0])\n",
    "        \n",
    "        if x.shape[0] < 10000:\n",
    "            continue\n",
    "        if len(np.unique(y)) > 2:\n",
    "            continue\n",
    "\n",
    "        for bptt_ in [500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, 10000]:\n",
    "            bptt_ = bptt_ // 2\n",
    "            #model = classifier_dict[classifier_key]\n",
    "            x_, y_ = x.copy(), y.copy()\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x_, y_, test_size=0.5, random_state=split)\n",
    "            x_train, y_train = x_train[0:bptt_], y_train[0:bptt_]\n",
    "            model.fit(x_train, y_train) # ranking[0:j]\n",
    "            pred = model.predict_proba(x_test) # ranking[0:j]\n",
    "            ce = tabular_metrics.auc_metric(y_test, pred)\n",
    "            ces += [{'bptt': bptt_, 'k': k, 'm': float(ce), 'method': classifier_key, 'split': split}]\n",
    "            print(x_train.shape, ce)\n",
    "    with open(f'generalization_{classifier_key}_{split}.obj',\"wb\") as fh:\n",
    "        pickle.dump(ces,fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen('tabpfn', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ces = []\n",
    "for classifier_key in classifier_dict:\n",
    "    for split in range(0,5):\n",
    "        try:\n",
    "            with open(f'generalization_{classifier_key}_{split}.obj',\"rb\") as fh:\n",
    "                ces += pickle.load(fh)\n",
    "        except:\n",
    "            pass\n",
    "df = pd.DataFrame(ces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(['bptt', 'split', 'method']).mean().reset_index()\n",
    "fig, ax = plt.subplots(1,1, figsize=(8, 6)) # , sharey=True\n",
    "\n",
    "colors = iter(sns.color_palette(\"tab10\"))\n",
    "for classifier_key in ['tabpfn']:#df.method.unique():\n",
    "    c = next(colors)\n",
    "    sns.lineplot(x='bptt', y='m', data=df[df.method==classifier_key], label=relabeler[classifier_key], color=c, ax = ax)\n",
    "    #ax.text(x = df[df.method==classifier_key].iloc[50].bptt, # x-coordinate position of data label\n",
    "    # y = df[df.method==classifier_key].iloc[50].m, # y-coordinate position of data label, adjusted to be 150 below the data point\n",
    "    # s = classifier_key, # data label, formatted to ignore decimals\n",
    "    # color = c, size=12) # set colour of line\n",
    "    \n",
    "ax.get_legend().remove()\n",
    "ax.set(xlabel='Number of training samples')\n",
    "ax.set(ylabel='ROC AUC')\n",
    "plt.axvline(x=1024, linestyle='dashed', color='red')\n",
    "plt.ylim((0.73,0.79))\n",
    "plt.xlim((250,5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabpfn",
   "language": "python",
   "name": "tabpfn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
